{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7a37e4",
   "metadata": {},
   "source": [
    "# Recommender System\n",
    "\n",
    "## Collaborative Filtering\n",
    "\n",
    "With Collaborative filtering we make predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption is that if a user A has the same opinion as a user B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a user chosen randomly.\n",
    "\n",
    "The image below (from Wikipedia) shows an example of collaborative filtering. At first, people rate different items (like videos, images, games). Then, the system makes predictions about a user's rating for an item not rated yet. The new predictions are built upon the existing ratings of other users with similar ratings with the active user. In the image, the system predicts that the user will not like the video.\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/5/52/Collaborative_filtering.gif />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8d8f16",
   "metadata": {},
   "source": [
    "Spark MLlib library for Machine Learning provides a Collaborative Filtering implementation by using Alternating Least Squares. The implementation in MLlib has these parameters:\n",
    "\n",
    "* numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "* rank is the number of latent factors in the model.\n",
    "* iterations is the number of iterations to run.\n",
    "* lambda specifies the regularization parameter in ALS.\n",
    "* implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "* alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab0d35",
   "metadata": {},
   "source": [
    "### Importing PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f088be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.1.1-bin-hadoop3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2c4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63812dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('recommender_system').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb6e6d",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f10225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('movielens_ratings.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5354afe",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d8215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|movieId|rating|userId|\n",
      "+-------+------+------+\n",
      "|      2|   3.0|     0|\n",
      "|      3|   1.0|     0|\n",
      "|      5|   2.0|     0|\n",
      "|      9|   4.0|     0|\n",
      "|     11|   1.0|     0|\n",
      "+-------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903783a9",
   "metadata": {},
   "source": [
    "### Shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8003b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1501, 3)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(),len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6bc806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573a79d",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369bb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d5e6386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|movieId|rating|userId|\n",
      "+-------+------+------+\n",
      "|      0|     0|     0|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb0f4d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movieId', 'rating', 'userId']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "097a624c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|           movieId|            rating|            userId|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|              1501|              1501|              1501|\n",
      "|   mean| 49.40572951365756|1.7741505662891406|14.383744170552964|\n",
      "| stddev|28.937034065088994| 1.187276166124803| 8.591040424293272|\n",
      "|    min|                 0|               1.0|                 0|\n",
      "|    max|                99|               5.0|                29|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b8436",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec37a4",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8308a",
   "metadata": {},
   "source": [
    "We can do a split to evaluate how well our model performed, but keep in mind that it is very hard to know conclusively how well a recommender system is truly working for some topics. Especially if subjectivity is involved, for example not everyone that loves star wars is going to love star trek, even though a recommendation system may suggest otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78307be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , test_data = df.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b24b2e",
   "metadata": {},
   "source": [
    "### ALS Recommender Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df31f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f583f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default as per documentation\n",
    "als = ALS(maxIter=5,regParam=0.01,userCol='userId',itemCol='movieId',ratingCol='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76cfadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91782bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "373610a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|movieId|rating|userId|prediction|\n",
      "+-------+------+------+----------+\n",
      "|     31|   1.0|    26| 2.0119586|\n",
      "|     31|   1.0|    13| 1.9506198|\n",
      "|     85|   2.0|    20| 2.7528925|\n",
      "|     85|   1.0|    15| 1.4837852|\n",
      "|     85|   5.0|     8| 3.9929185|\n",
      "+-------+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)\n",
    "\n",
    "#eg- rating is 1 but my model predicted rating of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3291ca",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa3edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eebad8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the rating column with predicted column\n",
    "evaluator = RegressionEvaluator(metricName='rmse',labelCol='rating',predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f55e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0bca36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE\n",
      "1.872653449708343\n"
     ]
    }
   ],
   "source": [
    "print('RMSE')\n",
    "print(rmse)\n",
    "\n",
    "#Not great due to less data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f6e19e",
   "metadata": {},
   "source": [
    "### Recommendation for Specific User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "505f81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_user = test_data.filter(test_data['userId']==11).select(['movieId','userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e7d30d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieId|userId|\n",
      "+-------+------+\n",
      "|     37|    11|\n",
      "|     39|    11|\n",
      "|     48|    11|\n",
      "|     66|    11|\n",
      "|     77|    11|\n",
      "|     81|    11|\n",
      "|     82|    11|\n",
      "|     97|    11|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a361072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.transform(single_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dabeba9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+\n",
      "|movieId|userId| prediction|\n",
      "+-------+------+-----------+\n",
      "|     77|    11|   4.991973|\n",
      "|     48|    11|  1.8184073|\n",
      "|     66|    11|  1.8100948|\n",
      "|     81|    11|  1.7049825|\n",
      "|     82|    11|  1.3522993|\n",
      "|     97|    11|  1.3498913|\n",
      "|     37|    11|  0.8737135|\n",
      "|     39|    11|-0.65319556|\n",
      "+-------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations.orderBy('prediction',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb5c7c",
   "metadata": {},
   "source": [
    "**This means that userId 11 will like the movieID 77 very much as the predicted rating is almost 5 and so on for other movies**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
